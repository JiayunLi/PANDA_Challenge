{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "## sys package\n",
    "import os, sys\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used\n",
    "sys.path.append(\"./prediction_models/input/prostate-cancer-grade-assessment/\")\n",
    "## warning off\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## general package\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "# print(device)\n",
    "\n",
    "## customized package\n",
    "from input.inputPipeline import *\n",
    "from model.resnext_ssl import Model_Infer as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = './input/prostate-cancer-grade-assessment/train_images'\n",
    "TEST = './input/prostate-cancer-grade-assessment/train.csv'\n",
    "SAMPLE = './input/prostate-cancer-grade-assessment/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([0.90949707, 0.8188697, 0.87795304])\n",
    "std = torch.tensor([0.36357649, 0.49984502, 0.40477625])\n",
    "tsfm = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=mean,\n",
    "                              std=std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "weights = [f'./train/weights/Resnext50_reg_medreso_12patch/Resnext50_reg_medreso_12patch_{i}_best.pth.tar' for i in range(4)]\n",
    "for path in weights:\n",
    "#     state_dict = torch.load(path,map_location=torch.device('cpu'))\n",
    "    state_dict = torch.load(path)\n",
    "    model = Model(n = 1)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.float()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "del state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c490fc79fd51424691ae0a6d84c74f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2654.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>isup_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id  isup_grade\n",
       "0  0005f7aaab2800f6170c399693a96917           0\n",
       "1  000920ad0b612851f8e01bcc880d9b3d           0\n",
       "2  0018ae58b01bdadc8e347995b69f99aa           5\n",
       "3  001c62abd11fa4b57bf7a6c603a11bb9           4\n",
       "4  001d865e65ef5d2579c190a0e0350d8f           0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv(SAMPLE)\n",
    "## if there are data in \"test_images\", (only happens when you submit your notebook, do inference)\n",
    "if os.path.exists(DATA):\n",
    "    sz = 256\n",
    "    bs = 4\n",
    "    dataset = PandaPatchDatasetInfer(TEST, DATA, transform=tsfm, sz = sz)\n",
    "    dataloader = DataLoader(dataset, batch_size=bs,\n",
    "                            shuffle=False, num_workers=0, collate_fn=dataloader_collte_fn_infer)\n",
    "    names,preds = [],[] ## record image names and predictions\n",
    "    ## Model inference\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tqdm(dataloader), start = 0):\n",
    "            if idx > 50:\n",
    "                break\n",
    "            img, name = data\n",
    "            img = img.float().to(device)\n",
    "            bs,N,C,h,w = img.shape\n",
    "#             print(bs, N, C, h, w)\n",
    "            ## dihedral TTA\n",
    "            img = torch.stack([img,img.flip(-1),img.flip(-2),img.flip(-1,-2),\n",
    "                  img.transpose(-1,-2),img.transpose(-1,-2).flip(-1),\n",
    "                  img.transpose(-1,-2).flip(-2),img.transpose(-1,-2).flip(-1,-2)],1)\n",
    "            img = img.view(-1, N, C, h, w)\n",
    "            p = [model(img) for model in models] # [4, bs * 8, 6]\n",
    "            p = torch.stack(p,1) # [bs * 8, 4, 1]\n",
    "            p = p.view(bs,8*len(models),-1) # [bs, 8(augmentation) * 4 (model), 1]\n",
    "#             p = p.mean(1).argmax(-1).cpu() #[bs]\n",
    "            p = p.mean(1).round().squeeze().to(torch.int64).clamp_(min=0, max=5).cpu() #[bs]\n",
    "            names.append(name)\n",
    "            preds.append(p)\n",
    "        names = np.concatenate(names)\n",
    "        preds = torch.cat(preds).numpy()\n",
    "        sub_df = pd.DataFrame({'image_id': names, 'isup_grade': preds})\n",
    "\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df['isup_grade'].dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
